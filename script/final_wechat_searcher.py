#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆç‰ˆå¾®ä¿¡å…¬ä¼—å·æœç´¢å™¨
ç®€åŒ–æ•°æ®å¤„ç†ï¼Œä¸“æ³¨äºç¨³å®šæ€§
"""

import time
import random
import requests
import os
import json
import csv
import hashlib
from datetime import datetime
from urllib.parse import quote

class FinalWeChatSearcher:
    """
    æœ€ç»ˆç‰ˆæœç´¢å™¨ - ç®€åŒ–ä¸”ç¨³å®š
    """
    
    def __init__(self, gzh_name):
        self.gzh_name = gzh_name
        self.searching = True
        self.total_articles_fetched = 0
        self.session = requests.Session()
        self.articles_data = []
        
        # ç”Ÿæˆ32ä½fingerprint
        self.fingerprint = self._generate_fingerprint()
        
        try:
            self.login_info = self._load_cookie()
            self._setup_session()
            print(f"ğŸ” ç”Ÿæˆçš„32ä½Fingerprint: {self.fingerprint}")
        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            self.searching = False

    def _generate_fingerprint(self):
        """ç”Ÿæˆ32ä½fingerprint"""
        # ä½¿ç”¨æ—¶é—´æˆ³å’Œéšæœºæ•°ç”Ÿæˆç¨³å®šçš„fingerprint
        timestamp = int(time.time() * 1000)
        random_part = random.randint(100000, 999999)
        combined = f"fingerprint_{timestamp}_{random_part}"
        return hashlib.md5(combined.encode('utf-8')).hexdigest()

    def _load_cookie(self):
        """åŠ è½½Cookie"""
        cookies_dir = 'cookies'
        sub_dirs = [d for d in os.listdir(cookies_dir) if os.path.isdir(os.path.join(cookies_dir, d))]
        account_dir = os.path.join(cookies_dir, sub_dirs[0])
        cookie_file_path = os.path.join(account_dir, 'cookie.json')

        with open(cookie_file_path, 'r', encoding='utf-8') as f:
            login_info = json.load(f)
            
        print(f"âœ… åŠ è½½Cookieè´¦å·: {os.path.basename(account_dir)}")
        return login_info

    def _setup_session(self):
        """è®¾ç½®ä¼šè¯"""
        self.session.headers.update({
            'accept': '*/*',
            'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7,ja;q=0.6',
            'accept-encoding': 'gzip, deflate, br, zstd',
            'cookie': self.login_info['cookie'],
            'priority': 'u=1, i',
            'referer': f'https://mp.weixin.qq.com/cgi-bin/appmsg?t=media/appmsg_edit_v2&action=edit&isNew=1&type=77&createType=0&token={self.login_info["token"]}&lang=zh_CN&timestamp=1756885829443',
            'sec-ch-ua': '"Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
            'x-requested-with': 'XMLHttpRequest'
        })

    def _make_request(self, url):
        """å‘é€è¯·æ±‚"""
        try:
            time.sleep(random.uniform(1.0, 2.0))
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    if 'base_resp' in data:
                        ret_code = data['base_resp'].get('ret', 0)
                        if ret_code == 0:
                            return data
                        elif ret_code == 200013:
                            print(f"âš ï¸ é‡åˆ°200013é”™è¯¯ï¼Œé‡æ–°ç”Ÿæˆfingerprint")
                            self.fingerprint = self._generate_fingerprint()
                            print(f"ğŸ”„ æ–°fingerprint: {self.fingerprint}")
                            return None
                        else:
                            print(f"âŒ APIé”™è¯¯: {ret_code}")
                            return None
                    else:
                        return data
                except json.JSONDecodeError:
                    print(f"âŒ JSONè§£æå¤±è´¥")
                    return None
            else:
                print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def search_gzh(self, gzh_name):
        """æœç´¢å…¬ä¼—å·"""
        encoded_name = quote(gzh_name)
        search_url = f'https://mp.weixin.qq.com/cgi-bin/searchbiz?action=search_biz&token={self.login_info["token"]}&lang=zh_CN&f=json&ajax=1&random={time.time()}&query={encoded_name}&begin=0&count=5&fingerprint={self.fingerprint}'
        
        data = self._make_request(search_url)
        if not data or not data.get('list'):
            return None

        gzh_data = data['list'][0]
        return {
            'name': gzh_data['nickname'],
            'fakeid': gzh_data['fakeid'],
            'avatar_url': gzh_data['round_head_img'],
            'signature': gzh_data['signature']
        }

    def get_articles(self, fakeid, begin=0, count=5):
        """è·å–æ–‡ç« åˆ—è¡¨"""
        
        # ä½¿ç”¨æ–°æ¥å£
        new_url = f'https://mp.weixin.qq.com/cgi-bin/appmsgpublish?sub=list&search_field=null&begin={begin}&count={count}&query=&fakeid={fakeid}&type=101_1&free_publish_type=1&sub_action=list_ex&fingerprint={self.fingerprint}&token={self.login_info["token"]}&lang=zh_CN&f=json&ajax=1'
        
        data = self._make_request(new_url)
        if data:
            return data, 'new'
        
        return None, None

    def _process_page_data(self, data, api_type, page_num):
        """å¤„ç†é¡µé¢æ•°æ® - æ ¹æ®æ–°APIæ ¼å¼è§£æ"""
        page_articles = []
        
        try:
            # åªå¤„ç†æ–°æ¥å£æ•°æ®
            if api_type == 'new' and 'publish_page' in data:
                try:
                    # è§£æpublish_pageå­—ç¬¦ä¸²
                    publish_page_data = json.loads(data['publish_page'])
                    
                    # è·å–æ–‡ç« ç»Ÿè®¡ä¿¡æ¯
                    total_count = publish_page_data.get('total_count', 0)
                    publish_count = publish_page_data.get('publish_count', 0)
                    masssend_count = publish_page_data.get('masssend_count', 0)
                    
                    print(f"   ï¿½ ç»Ÿè®¡ä¿¡æ¯:")
                    print(f"      æ€»æ–‡ç« æ•°: {total_count}")
                    print(f"      å‘è¡¨æ€»æ•°: {publish_count}")
                    print(f"      ç¾¤å‘æ€»æ•°: {masssend_count}")
                    
                    # å¤„ç†æ–‡ç« åˆ—è¡¨
                    if 'publish_list' in publish_page_data:
                        for item in publish_page_data['publish_list']:
                            if isinstance(item, dict) and 'publish_info' in item:
                                try:
                                    # è§£ææ¯ç¯‡æ–‡ç« çš„publish_info
                                    publish_info = json.loads(item['publish_info'])
                                    if 'appmsgex' in publish_info and publish_info['appmsgex']:
                                        # æå–æ–‡ç« ä¿¡æ¯
                                        for article in publish_info['appmsgex']:
                                            article_data = {
                                                'title': article.get('title', 'æ— æ ‡é¢˜'),
                                                'cover': article.get('cover', ''),
                                                'content_url': article.get('link', ''),
                                                'update_time': article.get('update_time', 0),
                                                'itemidx': article.get('itemidx', 0),
                                                'author': article.get('author_name', ''),
                                                'digest': article.get('digest', ''),
                                                'publish_time': datetime.fromtimestamp(article.get('update_time', 0)).strftime('%Y-%m-%d %H:%M:%S'),
                                                'publish_type': item.get('publish_type', 0)
                                            }
                                            page_articles.append(article_data)
                                except json.JSONDecodeError:
                                    print(f"   âš ï¸ è§£ææ–‡ç« ä¿¡æ¯å¤±è´¥")
                                    continue
                
                except json.JSONDecodeError as e:
                    print(f"   âŒ è§£æpublish_pageå¤±è´¥: {e}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ç« ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if not page_articles:
                print(f"   âš ï¸ æœªæ‰¾åˆ°æ–‡ç« æ•°æ®")
                print(f"   æ•°æ®æ ·æœ¬: {str(data)[:300]}...")
        
        except Exception as e:
            print(f"   âŒ å¤„ç†ç¬¬{page_num}é¡µæ•°æ®å¤±è´¥: {e}")
        
        return page_articles

    def _extract_article_from_dict(self, item):
        """ä»å­—å…¸ä¸­æå–æ–‡ç« ä¿¡æ¯"""
        try:
            # å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
            title = item.get('title') or item.get('subject') or 'æ— æ ‡é¢˜'
            
            # å¦‚æœæœ‰publish_infoå­—æ®µï¼Œå°è¯•è§£æ
            if 'publish_info' in item:
                try:
                    publish_info_str = item['publish_info']
                    if isinstance(publish_info_str, str):
                        publish_info = json.loads(publish_info_str)
                        if 'appmsgex' in publish_info and publish_info['appmsgex']:
                            # å–ç¬¬ä¸€ç¯‡æ–‡ç« 
                            appmsg = publish_info['appmsgex'][0]
                            return {
                                'title': appmsg.get('title', title),
                                'digest': appmsg.get('digest', ''),
                                'content_url': appmsg.get('content_url', ''),
                                'source_url': appmsg.get('source_url', ''),
                                'cover': appmsg.get('cover', ''),
                                'author': appmsg.get('author', ''),
                                'copyright_stat': appmsg.get('copyright_stat', 0),
                                'duration': appmsg.get('duration', 0),
                                'type': 'main',
                                'publish_time': datetime.fromtimestamp(item.get('sent_info', {}).get('time', 0)).strftime('%Y-%m-%d %H:%M:%S') if isinstance(item.get('sent_info'), dict) and item.get('sent_info', {}).get('time') else 'æœªçŸ¥æ—¶é—´',
                                'publish_timestamp': item.get('sent_info', {}).get('time', 0) if isinstance(item.get('sent_info'), dict) else 0,
                                'msgid': item.get('msgid', ''),
                                'publish_type': item.get('publish_type', 0)
                            }
                except (json.JSONDecodeError, KeyError, TypeError):
                    pass
            
            # å¦‚æœæ²¡æœ‰publish_infoæˆ–è§£æå¤±è´¥ï¼Œç›´æ¥ä»itemæå–
            if title != 'æ— æ ‡é¢˜':
                return {
                    'title': title,
                    'digest': item.get('digest', ''),
                    'content_url': item.get('link', item.get('content_url', '')),
                    'source_url': item.get('source_url', ''),
                    'cover': item.get('cover', ''),
                    'author': item.get('author', ''),
                    'copyright_stat': item.get('copyright_stat', 0),
                    'duration': item.get('duration', 0),
                    'type': 'main',
                    'publish_time': datetime.fromtimestamp(item.get('create_time', item.get('time', 0))).strftime('%Y-%m-%d %H:%M:%S') if item.get('create_time', item.get('time', 0)) else 'æœªçŸ¥æ—¶é—´',
                    'publish_timestamp': item.get('create_time', item.get('time', 0)),
                    'msgid': item.get('msgid', ''),
                    'publish_type': item.get('publish_type', 0)
                }
        
        except Exception as e:
            print(f"   âš ï¸ æå–æ–‡ç« ä¿¡æ¯å¤±è´¥: {e}")
        
        return None

    def search_all_articles(self):
        """æœç´¢æ‰€æœ‰æ–‡ç« """
        if not self.searching:
            return
            
        try:
            # æœç´¢å…¬ä¼—å·
            print(f"ğŸ” æœç´¢å…¬ä¼—å·: {self.gzh_name}")
            gzh_info = self.search_gzh(self.gzh_name)
            if not gzh_info:
                print(f"âŒ æœªæ‰¾åˆ°å…¬ä¼—å·: {self.gzh_name}")
                return
            
            print(f"âœ… æ‰¾åˆ°å…¬ä¼—å·: {gzh_info['name']}")
            print(f"   ç®€ä»‹: {gzh_info['signature']}")
            print(f"   FakeID: {gzh_info['fakeid']}")
            print("=" * 60)
            
            fakeid = gzh_info['fakeid']
            
            # è·å–ç¬¬ä¸€é¡µç¡®å®šæ€»æ•°å’ŒAPIç±»å‹
            first_page_data, api_type = self.get_articles(fakeid, 0, 5)
            if not first_page_data:
                print("âŒ è·å–ç¬¬ä¸€é¡µå¤±è´¥")
                return
            
            print(f"ğŸ“¡ ä½¿ç”¨APIç±»å‹: {api_type}")
            
            # è§£ææ€»æ–‡ç« æ•°
            publish_page_data = json.loads(first_page_data.get('publish_page', '{}'))
            total_articles = publish_page_data.get('total_count', 0)
            
            if total_articles == 0:
                print("âš ï¸ æ— æ³•ç¡®å®šæ–‡ç« æ€»æ•°ï¼Œå°†ç»§ç»­è·å–ç›´åˆ°æ²¡æœ‰æ›´å¤šæ–‡ç« ")
                total_pages = 1000  # è®¾ç½®ä¸€ä¸ªè¶³å¤Ÿå¤§çš„å€¼
            else:
                total_pages = (total_articles + 4) // 5
                print(f"ğŸ“Š è¯¥å…¬ä¼—å·å…±æœ‰ {total_articles} ç¯‡æ–‡ç« ï¼Œåˆ†ä¸º {total_pages} é¡µ")
            
            print("ğŸš€ å¼€å§‹è·å–æ–‡ç« ...")
            print("=" * 60)
            
            # å¤„ç†ç¬¬ä¸€é¡µæ•°æ®
            page_articles = self._process_page_data(first_page_data, api_type, 1)
            self._display_articles(page_articles, 1)
            
            # é€é¡µè·å–æ–‡ç« ï¼Œè·å–æ‰€æœ‰é¡µé¢ç›´åˆ°ç»“æŸ
            for page_num in range(1, total_pages):
                if not self.searching:
                    break
                
                print(f"ğŸ“„ è·å–ç¬¬ {page_num + 1} é¡µ...")
                
                offset = page_num * 5
                page_data, current_api_type = self.get_articles(fakeid, offset, 5)
                
                if not page_data:
                    print(f"âŒ ç¬¬ {page_num + 1} é¡µè·å–å¤±è´¥")
                    break
                
                # è§£æé¡µé¢æ•°æ®
                page_articles = self._process_page_data(page_data, current_api_type, page_num + 1)
                
                # å¦‚æœè¿ç»­3æ¬¡æ²¡æœ‰è·å–åˆ°æ–‡ç« ï¼Œåˆ™è®¤ä¸ºå·²ç»åˆ°è¾¾æœ«å°¾
                if not page_articles:
                    print(f"âš ï¸ ç¬¬ {page_num + 1} é¡µæ— æ–‡ç« æ•°æ®")
                    # å†å°è¯•3æ¬¡
                    retry_count = 0
                    for _ in range(3):
                        time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                        page_data, current_api_type = self.get_articles(fakeid, offset, 5)
                        if page_data:
                            page_articles = self._process_page_data(page_data, current_api_type, page_num + 1)
                            if page_articles:
                                break
                        retry_count += 1
                    
                    if retry_count >= 3:
                        print(f"âš ï¸ è¿ç»­{retry_count}æ¬¡æœªè·å–åˆ°æ–‡ç« ï¼Œå¯èƒ½å·²åˆ°æœ«å°¾")
                        break
                
                self._display_articles(page_articles, page_num + 1)
                
                # æ¯10é¡µæ˜¾ç¤ºè¿›åº¦
                if (page_num + 1) % 10 == 0:
                    print(f"ğŸ“ˆ å·²è·å– {page_num + 1} é¡µï¼Œç´¯è®¡ {self.total_articles_fetched} ç¯‡æ–‡ç« ")
                
                # ç”¨æˆ·æ§åˆ¶
                if (page_num + 1) % 20 == 0:
                    user_input = input(f"\nå·²è·å–{page_num + 1}é¡µï¼Œç»§ç»­ï¼Ÿ(å›è½¦=ç»§ç»­, q=é€€å‡º): ")
                    if user_input.lower() == 'q':
                        break
            
            print(f"\nğŸ‰ æœç´¢å®Œæˆï¼")
            print(f"   æ€»å…±è·å–äº† {self.total_articles_fetched} ç¯‡æ–‡ç« ")
            
            # ä¿å­˜ç»“æœ
            self._save_results()
            
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.searching = False

    def _display_articles(self, page_articles, page_num):
        """æ˜¾ç¤ºæ–‡ç« ä¿¡æ¯"""
        if page_articles:
            print(f"   âœ… è§£æåˆ° {len(page_articles)} ç¯‡æ–‡ç« ")
            for article in page_articles:
                self.total_articles_fetched += 1
                print(f"      [{self.total_articles_fetched}] {article['title']}")
                print(f"          å‘å¸ƒæ—¶é—´: {article['publish_time']}")
                if article['author']:
                    print(f"          ä½œè€…: {article['author']}")
                print()
                
                self.articles_data.append(article)

    def _save_results(self):
        """ä¿å­˜æœç´¢ç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ ¼å¼
        json_filename = f"final_search_{self.gzh_name}_{timestamp}.json"
        results = {
            'gzh_name': self.gzh_name,
            'total_articles': self.total_articles_fetched,
            'search_time': datetime.now().isoformat(),
            'fingerprint_used': self.fingerprint,
            'articles': self.articles_data
        }
        
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜CSVæ ¼å¼
        csv_filename = f"final_search_{self.gzh_name}_{timestamp}.csv"
        with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['åºå·', 'æ ‡é¢˜', 'å‘å¸ƒæ—¶é—´', 'ä½œè€…', 'æ‘˜è¦', 'é“¾æ¥'])
            
            for i, article in enumerate(self.articles_data, 1):
                writer.writerow([
                    i,
                    article['title'],
                    article['publish_time'],
                    article['author'],
                    article['digest'],
                    article['content_url']
                ])
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜:")
        print(f"   JSON: {json_filename}")
        print(f"   CSV:  {csv_filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æœ€ç»ˆç‰ˆå¾®ä¿¡å…¬ä¼—å·æœç´¢å™¨")
    print("âœ… åŒæ¥å£æ”¯æŒï¼Œè‡ªåŠ¨åˆ‡æ¢")
    print("âœ… 32ä½fingerprintç”Ÿæˆ")
    print("âœ… ç¨³å®šçš„æ•°æ®è§£æ")
    print("=" * 60)
    
    gzh_name = input("è¯·è¾“å…¥è¦æœç´¢çš„å…¬ä¼—å·åç§°: ")
    if not gzh_name:
        print("âŒ å…¬ä¼—å·åç§°ä¸èƒ½ä¸ºç©º")
        return

    try:
        searcher = FinalWeChatSearcher(gzh_name)
        if searcher.searching:
            searcher.search_all_articles()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æœç´¢")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()