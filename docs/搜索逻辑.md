╭─ Response ───────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ 我已通读后端实现，下面是一份关于 /gzhaccount/search 与 /gzhaccount/list                                              │
│ 的“搜索文档”，从鉴权、参数、数据流、外部依赖、持久化到边界行为进行说明，方便你理解与使用。                           │
│                                                                                                                      │
│ 一、整体概览                                                                                                         │
│                                                                                                                      │
│                                                                                                                      │
│  • 模块位置                                                                                                          │
│     • 路由: app/api/v1/routes/gzhaccount.py                                                                          │
│     • 服务: app/services/gzhaccount.py                                                                               │
│     • 数据模型: app/models/mp_account.py, app/models/mp_article.py, app/models/cookie.py                             │
│     • 输入输出 Schema: app/schemas/gzhaccount.py                                                                     │
│  • 鉴权与依赖                                                                                                        │
│     • 两个接口均需要登录且必须是“已激活”用户: 依赖 require_active_user（OAuth2 + JWT，检查 ActivationStatus          │
│       和过期时间）                                                                                                   │
│     • 使用数据库会话 get_db 注入 SQLAlchemy Session                                                                  │
│  • 依赖前置                                                                                                          │
│     • 必须为当前用户准备一个“当前 cookie”（Cookie.is_current = True 且未过期）供服务端访问微信公众平台的接口         │
│     • Cookie 的来源由 cookie 登录流程生成（app/services/cookie.py），并落盘到 static/cookies// 下                    │
│                                                                                                                      │
│ 二、数据模型（简要）                                                                                                 │
│                                                                                                                      │
│  • MpAccount（表 mp_accounts）                                                                                       │
│     • name 唯一，biz（fakeid）唯一，owner_email 归属                                                                 │
│     • article_account 记录已抓取文章数量                                                                             │
│     • avatar_url、avatar（本地存储路径）                                                                             │
│  • MpArticle（表 mp_articles）                                                                                       │
│     • url 唯一（用于去重）                                                                                           │
│     • item_show_type 为 int（0/8/11 等，注意 0 是有效值）                                                            │
│     • mp_account 字段保存账号名称（和 MpAccount.name 关联）                                                          │
│  • Cookie（表 cookies）                                                                                              │
│     • token（对应公众平台 token）、owner_email、expire_time、local（本地 cookie 目录）、is_current 等                │
│                                                                                                                      │
│ 三、接口说明                                                                                                         │
│                                                                                                                      │
│  1 /gzhaccount/search                                                                                                │
│                                                                                                                      │
│  • 方法: POST                                                                                                        │
│  • 请求体:                                                                                                           │
│     • name: str（公众号名称，必填）                                                                                  │
│     • max_articles: int（要抓取的文章数，0 表示全量；默认 0）                                                        │
│  • 返回体:                                                                                                           │
│     • account: MpAccountOut | null                                                                                   │
│     • articles: MpArticleOut[]（仅包含本次抓取新入库的文章，不包含历史已有文章）                                     │
│  • 流程细节:                                                                                                         │
│     1 获取当前用户的“当前 cookie”                                                                                    │
│        • 查询 cookies 表中 owner_email = 当前用户 且 is_current = True                                               │
│        • 验证 expire_time > now，否则报错“当前cookie已过期，请重新登录”                                              │
│        • 从 cookie.local 目录加载 gzhcookies.cookie（pickle，内含 requests 的 cookie jar）                           │
│     2 搜索公众号（微信公众平台搜索）                                                                                 │
│        • GET                                                                                                         │
│          https://mp.weixin.qq.com/cgi-bin/searchbiz?action=search_biz&token={token}&...&query={name}&begin=0&count=5 │
│        • 取返回 list[0] 作为匹配账号（只取第一条）                                                                   │
│        • 提取 nickname（账号名）、fakeid（biz）、round_head_img（头像）、signature（简介）                           │
│        • 下载头像到 static/mp_accounts/<安全过滤后的昵称>/avatar.jpg（若 URL 为 http 则转 https）                    │
│     3 账号信息入库（Upsert）                                                                                         │
│        • 以 name 唯一检索 mp_accounts：                                                                              │
│           • 不存在则插入（name、biz、owner_email、avatar_url、avatar、description 等）                               │
│           • 存在则更新（biz、description、avatar_url、avatar、update_time）                                          │
│     4 抓取文章列表                                                                                                   │
│        • 入口: _fetch_articles_page(session, token, fakeid, begin, count=5)                                          │
│           • GET                                                                                                      │
│             https://mp.weixin.qq.com/cgi-bin/appmsgpublish?sub=list&...&fakeid={fakeid}&type=101_1&...&token={token} │
│             &...                                                                                                     │
│           • 返回 JSON 中的 publish_page -> publish_list[] -> publish_info(appmsgex[])                                │
│           • 解析出 title、cover、link、update_time、item_show_type                                                   │
│        • 全量抓取（max_articles=0）: 以 5 为步长翻页，直到空页或达到 total_count                                     │
│        • 限量抓取（max_articles>0）: 翻页直至累计“新增文章”数量达到 max_articles 或无更多（注意每页粒度为            │
│          5，可能略多于 max_articles，不做截断）                                                                      │
│     5 持久化文章（去重入库）                                                                                         │
│        • 以 url 唯一查重，存在则跳过；新文章入库                                                                     │
│        • item_show_type 可能为 0，严禁用“or”导致 0 被当空，代码使用显式整型转换                                      │
│        • publish_date 存成 ISO 字符串（基于 update_time 的时间戳）                                                   │
│     6 更新账号统计                                                                                                   │
│        • 以 SQL count(mp_articles where mp_account=name) 更新 MpAccount.article_account                              │
│     7 返回值                                                                                                         │
│        • account: 入库或更新后的 MpAccount                                                                           │
│        • articles: “本次抓取新增入库”的 MpArticle 列表（仅新数据，不含历史数据）                                     │
│  • 错误与边界                                                                                                        │
│     • 无 cookie 或 cookie 过期 -> 400（ValueError -> HTTPException）                                                 │
│     • 微信搜索无结果 -> 返回 account=null, articles=[]                                                               │
│     • 解析失败/网络异常：fetch 时会优雅退化（返回空页、None total_count），最终导致抓取提前结束                      │
│                                                                                                                      │
│  2 /gzhaccount/list                                                                                                  │
│                                                                                                                      │
│  • 方法: GET                                                                                                         │
│  • 查询参数:                                                                                                         │
│     • name: str（公众号名称，必填）                                                                                  │
│     • offset: int（默认 0，>=0）                                                                                     │
│     • limit: int（默认 20，1..50）                                                                                   │
│  • 返回体:                                                                                                           │
│     • items: MpArticleOut[]（按 create_time 降序分页）                                                               │
│     • total: int（该公众号文章总数）                                                                                 │
│     • name, offset, limit 回显                                                                                       │
│  • 流程细节:                                                                                                         │
│     1 确认账号存在（按 name 精确匹配 mp_accounts）                                                                   │
│        • 若不存在：抛出 “先执行 /gzhaccount/search 完成账号建档，再获取文章列表”                                     │
│     2 仅从本地数据库分页读取（desc(create_time), offset, limit）                                                     │
│     3 total 为 count(mp_articles where mp_account=name)                                                              │
│  • 错误与边界                                                                                                        │
│     • 账号未建档 -> 400（ValueError -> HTTPException）                                                               │
│     • 不做实际远端刷新，仅读本地 DB                                                                                  │
│                                                                                                                      │
│ 四、外部依赖的微信接口                                                                                               │
│                                                                                                                      │
│  • 账号搜索: /cgi-bin/searchbiz?action=search_biz                                                                    │
│     • 关键参数: token、query、begin、count、lang、ajax、random                                                       │
│  • 已发布文章列表: /cgi-bin/appmsgpublish?sub=list&sub_action=list_ex                                                │
│     • 关键参数: fakeid（即 biz/fakeid）、begin、count、type=101_1、free_publish_type=1、token、fingerprint           │
│                                                                                                                      │
│ 五、持久化与静态资源                                                                                                 │
│                                                                                                                      │
│                                                                                                                      │
│                                                                                                                      │
│  • Cookies                                                                                                           │
│     • static/cookies//gzhcookies.cookie（requests cookie jar 的 pickle）                                             │
│     • static/cookies//cookie.json（包含 token、cookie 字符串、创建/过期时间、账号名与头像等）                        │
│  • 公众号头像                                                                                                        │
│     • static/mp_accounts/<账号名清洗后>/avatar.jpg                                                                   │
│  • DB 去重                                                                                                           │
│     • 账号: name、biz 唯一索引                                                                                       │
│     • 文章: url 唯一索引；mp_account 建有索引                                                                        │
│                                                                                                                      │
│ 六、返回数据结构（简要）                                                                                             │
│                                                                                                                      │
│  • MpAccountOut                                                                                                      │
│     • id, name, biz, description, category_id, owner_email, create_time, update_time, avatar_url, avatar,            │
│       article_account                                                                                                │
│  • MpArticleOut                                                                                                      │
│     • id, title, url, cover_url, publish_date, item_show_type, mp_account, create_time                               │
│     • 注意: Schema 中 item_show_type 为 Optional[str]，模型是 int，序列化时会自动做类型适配                          │
│  • GzhSearchResponse                                                                                                 │
│     • account: MpAccountOut | null                                                                                   │
│     • articles: MpArticleOut[]                                                                                       │
│  • GzhListResponse                                                                                                   │
│     • items: MpArticleOut[], total: int, name: str, offset: int, limit: int                                          │
│                                                                                                                      │
│ 七、行为特性与注意点                                                                                                 │
│                                                                                                                      │
│  • “限量抓取”并不保证恰好等于 max_articles：按页抓取，每页 5 条，可能略多于目标值                                    │
│  • /gzhaccount/search 只返回“本次新增入库”的文章；历史已入库文章不会出现在返回里                                     │
│  • /gzhaccount/list 仅从 DB 读取，不做远端同步；若需要刷新最新文章，需要先调用 /gzhaccount/search                    │
│  • 账号归属与访问控制                                                                                                │
│     • MpAccount 记录有 owner_email，但 /gzhaccount/list 按 name 读取且未校验 owner_email 与当前用户的匹配            │
│     • 若系统多用户共享数据库，存在“只要知道 name 就可读该账号文章”的潜在越权风险（可考虑增强为按 owner_email + name  │
│       过滤）                                                                                                         │
│  • Cookie 使用                                                                                                       │
│     • search 使用 pickle 加载的 cookie jar，不依赖 header 里的字符串 Cookie                                          │
│     • 需要确保当前 cookie 未过期（88 小时默认）                                                                      │
│                                                                                                                      │
│ 八、典型调用示例                                                                                                     │
│                                                                                                                      │
│  • 搜索 + 抓取                                                                                                       │
│     • POST /gzhaccount/search                                                                                        │
│        • body: { "name": "某公众号", "max_articles": 0 }                                                             │
│        • 返回: account + 本次新增文章数组                                                                            │
│  • 列表读取                                                                                                          │
│     • GET /gzhaccount/list?name=某公众号&offset=0&limit=20                                                           │
│        • 返回: items + total                                                                                         │
│                                                                                                                      │
│ 九、可改进点（建议）                                                                                                 │
│                                                                                                                      │
│  • 访问控制：/gzhaccount/list 增加 owner_email 限制，保障只可访问本人账号文章                                        │
│  • 限量抓取：当 max_articles > 0 时，精确截断返回数量或在响应中明确“可能超量”的提示                                  │
│  • 配置项：将分页 count=5 提升为配置或入参                                                                           │
│  • 失败告警与日志：对远端返回异常/JSON 结构变更的情况增加日志与可观测性                                              │
│                                                                                                                      │
│ 是否需要我把这份“搜索文档”整理成一页 Confluence 页面保存起来，或创建一个 Jira 任务来跟踪“/gzhaccount/list            │
│ 越权读取风险”的修复？我可以帮你：                                                                                    │
│                                                                                                                      │
│  • 创建 Confluence 页面记录这份分析                                                                                  │
│  • 为访问控制和抓取精度改进创建 Jira 任务                                                                            │
│  • 起一个分支提交访问控制修复草案的 Pull Request 你希望我先做哪一项？                                                │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

>
我有个疑问，如果搜索公众号，之前只搜索过80篇，没有做过全量搜索，这个账号可能有500篇，那么当我输入比如200、300，比80数字更
大，那么这个适合抓取文章列表能否先从近期搜索到的80篇的本地数据库返回，然后再去请求微信的接口去调用更久远的剩余历史文章列
表？ 目前是否有这个机制，以及面对这种问题，如何解决

╭─ Response ───────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ 这是一个很好的问题。先给出结论：目前代码没有“先返回本地已有，再在后台继续补全历史”的机制；并且 /gzhaccount/search    │
│ 在“限量抓取”场景下，返回的也只是“本次新入库”的文章，不包含之前已入库的80篇。                                         │
│                                                                                                                      │
│ 现状梳理                                                                                                             │
│                                                                                                                      │
│  • /gzhaccount/list 只从本地数据库分页读取，不会调用微信接口做刷新。                                                 │
│  • /gzhaccount/search 的“限量抓取”逻辑：                                                                             │
│     • 按每页5条，从 begin=0 一直往后翻，直到“本次新入库的文章数量”达到 max_articles 或远端没有更多。                 │
│     • 已经在库的文章会被跳过，不计入“已抓取数量”，所以如果你把 max_articles                                          │
│       从80增大到200/300，它会继续往后翻页并新增入库，但是响应只包含“本次新增的文章”，不会包含原有的80条。            │
│     • 这意味着此次请求不会“立刻”返回已有的80条；要拿到这80条，应该调用 /gzhaccount/list。                            │
│                                                                                                                      │
│ 会发生什么（举例）                                                                                                   │
│                                                                                                                      │
│  • 假设库里已有80篇（最近历史），远端总数约500。                                                                     │
│  • 调用 /gzhaccount/search，max_articles=300：                                                                       │
│     • 服务会从第一页重新抓，前面若干页都是重复，入库为0，不计入 max_articles。                                       │
│     • 它会继续翻页直到找到新文章并入库，直到“新增入库数”到达300或遍历完远端。                                        │
│     • 响应只包含本次新增的文章，不包含原先的80篇。                                                                   │
│     • 同时，这一次会占用较长时间，因为会反复扫描头部的重复页面。                                                     │
│                                                                                                                      │
│ 如何实现“先返回本地，再继续补全历史”的体验                                                                           │
│                                                                                                                      │
│ 方案A：客户端编排（无后端改造）                                                                                      │
│                                                                                                                      │
│  • 步骤：                                                                                                            │
│     1 先调用 GET /gzhaccount/list?name=xxx&offset=0&limit=200（或分段滚动），立即拿到本地已有的80篇（或不足部分）。  │
│     2 并行发起 POST /gzhaccount/search，max_articles 设为一个较大的数（如 500 或 0 全量），让后端继续补全历史。      │
│     3 前端每隔几秒刷新 /gzhaccount/list，看到更多文章不断出现。                                                      │
│  • 优点：无需后端改造，立刻可用。                                                                                    │
│  • 缺点：需要前端协调两次调用；/search 返回的只是新增文章，前端通常不直接展示这个返回，而是继续调 /list。            │
│                                                                                                                      │
│ 方案B：后端支持“增量刷新（异步）”                                                                                    │
│                                                                                                                      │
│  • B1. 在 /gzhaccount/list 增加参数，例如 refresh_async=true, target_total=300                                       │
│     • 行为：接口先立即返回当前 DB 的分页结果，同时在后台启动一个补抓任务（继续从远端往回翻，直到 DB 总量 ≥           │
│       target_total 或无更多）。                                                                                      │
│     • 响应可加上字段：refreshing=true, requested_total=300, job_id=xxx，前端据此轮询 /gzhaccount/list                │
│       或查询任务状态。                                                                                               │
│     • 技术实现要点：                                                                                                 │
│        • FastAPI 的 BackgroundTasks 或引入任务系统（Celery/RQ/APScheduler）。                                        │
│        • 新增一个服务方法（例如 fetch_until_total），使用当前账号的 biz 和                                           │
│          cookie，从“预计的起点”开始抓取（见“抓取优化”）。                                                            │
│  • B2. 新增 /gzhaccount/refresh 接口                                                                                 │
│     • 专职触发后台补抓，参数 name、target_total（或 begin_from），接口立即返回 job_id。                              │
│     • 前端再用 /gzhaccount/list 展示已有内容，轮询直到补抓完成。                                                     │
│  • B3. 新增“组合接口”                                                                                                │
│     • /gzhaccount/list_plus 或 /gzhaccount/search_plus：返回“本地已有的前N条”+ 启动补抓任务。避免前端调用两次。      │
│                                                                                                                      │
│ 抓取优化建议（减少重复扫描）                                                                                         │
│                                                                                                                      │
│  • 当前 search_account 每次都从 begin=0 开始翻，前面大量页面会是重复数据。建议：                                     │
│     • 在 MpAccount 上增加若干状态字段，如 fetched_count、last_begin、last_fetch_time，记录上次已抓的远端偏移。       │
│     • 下次请求时从 last_begin（或 fetched_count 向下对齐页大小的 begin）开始抓，减少重复扫描。                       │
│     • 加入“重复页停止策略”：若连续 K 页都没有新入库（比如 K=3），可认为已经到达已缓存区域，提前停止或快进 begin。    │
│     • 支持“只拉剩余 X 条”的目标：如果本地已有80，需要达到300，目标新增=220，抓取到新增达到220就停。                  │
│                                                                                                                      │
│ 最小改动的后端实现思路（示意）                                                                                       │
│                                                                                                                      │
│  • 新增服务方法（伪代码）：                                                                                          │
│     • def fetch_until_total(owner_email, name, target_total):                                                        │
│        • 查账号（确保存在），取 biz，取当前 cookie                                                                   │
│        • curr_total = count(mp_articles where mp_account=name)                                                       │
│        • if curr_total >= target_total: return                                                                       │
│        • begin = derive_begin_from_state() 或者 0                                                                    │
│        • while curr_total < target_total:                                                                            │
│           • page, total_count = _fetch_articles_page(...)                                                            │
│           • new_items = _persist_articles(name, page)                                                                │
│           • curr_total += len(new_items)                                                                             │
│           • begin += 5                                                                                               │
│           • 终止条件：page 为空、或 total_count 不存在、或 begin >= total_count、或连续多页无新增                    │
│  • 将它包到 BackgroundTasks 中，在 /gzhaccount/list 中根据 refresh_async/target_total 触发。                         │
│                                                                                                                      │
│ 你现在可以怎么做                                                                                                     │
│                                                                                                                      │
│  • 立即可用的方式（无需改代码）：                                                                                    │
│     • 前端先调用 /gzhaccount/list 取本地已有，再并行调用 /gzhaccount/search（max_articles 设大），前端轮询           │
│       /gzhaccount/list，直到满足目标条数。                                                                           │
│  • 推荐的长期方案（需要少量开发）：                                                                                  │
│     • 在 /gzhaccount/list 加一个 refresh_async + target_total 参数，并用 BackgroundTasks 触发补抓；或者新增          │
│       /gzhaccount/refresh 接口。                                                                                     │
│     • 补充 MpAccount 的“增量抓取状态”记录，减少重复扫描。                                                            │
│                                                                                                                      │
│ 需要我：                                                                                                             │
│                                                                                                                      │
│  • 创建一个 Confluence 页面整理上述设计与改造方案？                                                                  │
│  • 为“增量刷新（异步）”与“抓取优化（记录 last_begin 等）”创建两个 Jira 任务跟踪？                                    │
│  • 直接在当前项目起一个分支，给 /gzhaccount/list 增加 refresh_async 和 target_total 改造，并提一个 Pull Request？    │
│                                                                                                                      │
│ 你希望先走哪一步：创建设计文档 / 创建任务 / 直接改代码出一个 PR，还是先进一步讨论方案细节？                          │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯